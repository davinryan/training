# Monitoring

## Configuring and interpreting logs
* What is logged
  * View actions performed by tenant administrators.
  * View operations performed via the Management API.
  * View authentications made by your users.
  * View intermittent errors that may be hard to find with quality assurance testing.
  * Capture forensic data for security purposes and to identify anomaly detection triggers.
  * Identify patterns in usage trends.
  * Check for authentication errors and Management API call errors.
  * Set up automatic log scanning to check for rate limit errors so that you can proactively address activity that hits rate limits before it impacts your users.
  * Correlate management API events to their initiating requests by matching X-Correlation-ID header values.
* Log Streaming and exporting - abilty to send to a tool of your choice for analysis
* Recommendation - Build daily histogram by filtering for the following event field for the following
  * Abnormal activity
    * f         Failed login
    * fcoa	    Failed cross-origin authentication
    * feccft    Failed exchange
    * fepft	    Failed exchange
    * fsa	    Failed silent authentication
    * fu	    Failed login (invalid email/username)
    * pla	    Pre-login assessment
    * sepft	    Success exchange
  * Rate of errors in login flow
    * s	        Login success
    * fu	    Failed login, invalid email/username
    * fp	    Failed login, incorrect password
  * Rate of attack protection events
    * limit_mu	Blocked IP address
    * limit_wc	Blocked account
    * pwd_leak	Breached password during login
    * signup_pwd_leak	Breached password during signup
    * reset_pwd_leak	Breached password during password recovery
  * Number of IPs producing errors and their locations
    * Observe ip address data in conjunction with fu event traffic to determine where the failure traffic is coming from
  * Adaptive MFA - gets attached to all login attempts
    * Locations: 
      * confidence - details/anomalyDetection/confidence = high/medium/low
      * prompts to indicate if MFA was required - details/prompts[]/name = mfa; details/anomalyDetection/confidence = medium
      * type of MFA - details/authenticator/type = totp (One time password)
* Management API Location
  * /api/v2/logs/{id} - get log by id
  * /api/v2/users/{user_id}/logs - get logs for a user
  * Search by Checkpoint
    * Query params
      * from - checkpoint from which to start fetching logs
      * take - how many logs after checkpoint / offset
    * Limitations (searching by checkpoint)
      * you will only get logs that you have permission for
      * logs are ordered by log_id rather than time
      * pagination is unbounded
  * Search logs by criteria
    * Query params
      * q - search query
      * page - zero based page number
      * per_page - number of results per page
      * sort - sort field i.e. field:order e.g. date:-1 (date descending)
      * fields - comma separated list of fields to include or exclude (depending on include_fields). Leave empty to get all fields
      * include_fields - comma separated list of fields to include in the result - true/false - true includes 'fields'
    * Limitations
      * 100 per page
      * 1000 max results to page through
      * Only these fields are searchable in private cloud
        * user, connection, application, type, ip
* Log retention
  * based on plan
    * Starter	            1 day
    * B2C Essentials	    5 days
    * B2C Professional	    10 days
    * B2B Essentials	    5 days
    * B2B Professional	    10 days
    * Enterprise	        30 days
* Log streams
  * Benefits
    * great for reacting to specific events
    * longer log retention times
  * Support
    * Datadog
    * Splunk
    * Sumo Logic
    * Mixpanel
    * Segment
    * Amazon event bridge
    * Azure event grid
    * Custom webhook
    * Many other minor ones
  * Limitations
    * Feature disabled automatically until you repair connection - Failure for your server to accept logs for 7 consecutive days
  * PII Obfuscation
    * Options
      * Masking - replaced with asterisks
      * xxHash - fast non-encrypted hash algorithm for reading on server once received
    * Fields
      * first_name
      * last_name
      * email
      * phone
      * address
      * username

## Evaluate rate limit policy, rate limit burst capability
* Basically how to determine when you are being rate limited
* An API has the following rate limit:
  * Burst Limit: 1000 requests per fixed window (Default: 1 second)
  * Sustained Rate Limit: 100 requests per second (on a fixed window)
  * This means
    * The sustained rate limit is 100 requests per second on a fixed window - refilled every second
    * Due to the fixed window, the bucket of requests is refilled every second
    * 1000 requests over 10 seconds
* Ways
  * Tenant logs
    * api_limit - triggered when rate limit is hit
    * api_limit_warning - triggered when rate limit is approaching
    * appi - public performance burst add-on exceeds their sustained auth api request rate of 100 requests per second
  * API responses - 429 responses
    * Headers are also added to response 
      * x-ratelimit-reset - time when rate limit will reset
      * x-ratelimit-limit - max number of requests available
      * x-ratelimit-remaining - number of requests remaining in the current rate limit window
  * SDK Error handling - standard errors
  * Error pages
* How to deal with it if you're stuck - Contact support center with full raw log and where issue was seen
* 

## Deploy changes through CLI, Terraform, and management API
* Steps
  1. Install - `npm install -g auth0-deploy-cli`
  2. Create a dedicated Auth0 application - M2M type, add Auth0 Management API
     * Configure scopes - read:*, create:*, update:* and delete:*
  3. Configure and Deploy CLI
     * Use config.json to configure CLI or set environment variables
     * Ensure these vars are available (refer to Settings for M2M application created above)
       * AUTH0_DOMAIN
       * AUTH0_CLIENT_ID
       * AUTH0_CLIENT_SECRET
  4. Call the Deploy CLI
     * export - `a0deploy export --config_file=config.json --format=yaml --output_folder=local` - this exports everyting
     * import - `a0deploy import --config_file=config.json --input_file=local/tenant.yaml` - this imports everything for a tenant
* More CLI commands and options here - https://auth0.com/docs/deploy-monitor/deploy-cli-tool/use-as-a-cli